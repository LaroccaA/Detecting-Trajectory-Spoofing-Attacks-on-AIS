{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200e8a47",
   "metadata": {},
   "source": [
    "# Modello LSMT (Long Short-Term Memory) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d2742",
   "metadata": {},
   "source": [
    "### Codice di Configurazione e Pre-Elaborazione per LSTM\n",
    "Questo blocco di codice svolge due funzioni principali: prepara l'ambiente di calcolo, ottimizzando l'uso della GPU con TensorFlow, e definisce i parametri cruciali per la lettura dei dati e la costruzione del modello LSTM (Long Short-Term Memory) per la previsione \n",
    "delle traiettorie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5896be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 12:51:06.012008: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-20 12:51:06.049014: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-20 12:51:06.877732: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Rilevata: 1 (Memory Growth Attiva)\n",
      "Mixed Precision (FP16) Attivata\n",
      "Configurazione completata.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pyarrow.parquet as pq\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision # Per la 4050\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Rilevata: {len(gpus)} (Memory Growth Attiva)\")\n",
    "        \n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        mixed_precision.set_global_policy(policy)\n",
    "        print(\"Mixed Precision (FP16) Attivata\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"ATTENZIONE:CPU.\")\n",
    "\n",
    "INPUT_DIR = '../Pre-Elaborazione Dati/Dataset' \n",
    "SCALER_PATH = 'scaler.joblib' \n",
    "COLONNE_FEATURES = ['Latitude', 'Longitude', 'SOG', 'COG']\n",
    "\n",
    "WINDOW_SIZE = 30  \n",
    "BATCH_SIZE = 64\n",
    "\n",
    "all_files = sorted(glob.glob(os.path.join(INPUT_DIR, '*.parquet')))\n",
    "TRAIN_FILES = all_files[0:16]\n",
    "VAL_FILES = all_files[16:20]\n",
    "TEST_FILES = all_files[20:24] \n",
    "\n",
    "print(\"Configurazione completata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502386b",
   "metadata": {},
   "source": [
    "### Pre-screening delle Traiettorie di Training e Valutazione del Timestep (Window Size)\n",
    "Questo blocco di codice svolge una funzione di analisi preliminare critica dei dati di training. Il suo scopo principale è determinare l'usabilità delle traiettorie in funzione della dimensione della finestra temporale (Window Size o Timestep), un iperparametro cruciale per il modello LSTM.\n",
    "Il codice segue tre fasi distinte:\n",
    "1. **Caricamento e Preparazione dei File di Training**:\n",
    "   il codice individua tutti i file di dati che contengono le traiettorie delle navi (i file Parquet) e ne seleziona un sottoinsieme specifico da utilizzare per il training. Quindi, definisce una lista di diverse lunghezze di finestra che vogliamo testare (ad esempio, se usiamo gli ultimi 30 punti per la previsione o gli ultimi 40).\n",
    "   \n",
    "2. **Misurazione delle Traiettorie**: il codice scorre l'intero set di training, identificando ogni singola traiettoria unica e,     soprattutto, contando esattamente quanti punti (o misure) essa contiene. In pratica, misura la lunghezza di ogni sequenza di navigazione.\n",
    "\n",
    "3. **Report di Usabilità**: il codice combina le lunghezze misurate con i timestep che vogliamo testare. Il risultato è un report statistico:\n",
    "   * Per ogni dimensione di finestra (ad esempio, 30 punti), il codice calcola quante traiettorie sono abbastanza lunghe (almeno 30 punti) e quindi utilizzabili per l'addestramento.\n",
    "\n",
    "   * Conseguentemente, calcola quante traiettorie sono troppo corte e devono essere scartate per quella specifica configurazione.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80885758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trovati 25 file .parquet in '../Pre-Elaborazione Dati/Dataset'\n",
      "Controllo iperparametri sui file di TRAINING\n",
      "  Processando blocco_000-segmentato.parquet\n",
      "  Processando blocco_001-segmentato.parquet\n",
      "  Processando blocco_002-segmentato.parquet\n",
      "  Processando blocco_003-segmentato.parquet\n",
      "  Processando blocco_004-segmentato.parquet\n",
      "  Processando blocco_005-segmentato.parquet\n",
      "  Processando blocco_006-segmentato.parquet\n",
      "  Processando blocco_007-segmentato.parquet\n",
      "  Processando blocco_008-segmentato.parquet\n",
      "  Processando blocco_009-segmentato.parquet\n",
      "  Processando blocco_010-segmentato.parquet\n",
      "  Processando blocco_011-segmentato.parquet\n",
      "  Processando blocco_012-segmentato.parquet\n",
      "  Processando blocco_013-segmentato.parquet\n",
      "  Processando blocco_014-segmentato.parquet\n",
      "  Processando blocco_015-segmentato.parquet\n",
      "\n",
      "I conteggi corrispondono.\n",
      "\n",
      "Risultati dell'analisi (su 4,369,967 traiettorie totali di TRAINING):\n",
      "---------------------------------------------------------------------------\n",
      "Window Size     | Traiettorie Usabili  | Traiettorie Scartate | % Usabili \n",
      "---------------------------------------------------------------------------\n",
      "10              | 2957346              | 1412621              | 67.67     %\n",
      "15              | 2678465              | 1691502              | 61.29     %\n",
      "20              | 2461683              | 1908284              | 56.33     %\n",
      "25              | 2283891              | 2086076              | 52.26     %\n",
      "30              | 2131706              | 2238261              | 48.78     %\n",
      "40              | 1882078              | 2487889              | 43.07     %\n",
      "---------------------------------------------------------------------------\n",
      "Analisi completata.\n"
     ]
    }
   ],
   "source": [
    "all_files = sorted(glob.glob(os.path.join(INPUT_DIR, '*.parquet')))\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    print(f\"ERRORE CRITICO: Nessun file .parquet trovato in '{INPUT_DIR}'\")\n",
    "else:\n",
    "    print(f\"Trovati {len(all_files)} file .parquet in '{INPUT_DIR}'\")\n",
    "\n",
    "TRAIN_FILES = all_files[0:16]\n",
    "IPERPARAMETRI_TIMESTEP = [10, 15, 20, 25, 30, 40]\n",
    "\n",
    "print(f\"Controllo iperparametri sui file di TRAINING\")\n",
    "\n",
    "total_counts_counter = Counter()\n",
    "total_ids_set = set()\n",
    "\n",
    "for file_path in TRAIN_FILES:\n",
    "    print(f\"  Processando {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        df = pd.read_parquet(file_path, columns=['TrajectoryID'])\n",
    "        \n",
    "        total_ids_set.update(df['TrajectoryID'].unique())\n",
    "        \n",
    "        total_counts_counter.update(df['TrajectoryID'])\n",
    "        \n",
    "        del df\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(f\"ERRORE lettura:{file_path}: {e}\")\n",
    "        \n",
    "\n",
    "conteggio_set = len(total_ids_set)\n",
    "conteggio_counter = len(total_counts_counter)\n",
    "\n",
    "if conteggio_set != conteggio_counter:\n",
    "    print(\"Errore:I conteggi non corrispondono. C'è ancora un problema.\")\n",
    "else:\n",
    "    print(\"\\nI conteggi corrispondono.\")\n",
    "    \n",
    "    all_lengths = list(total_counts_counter.values())\n",
    "    totale_traiettorie_analisi = conteggio_counter\n",
    "\n",
    "    print(f\"\\nRisultati dell'analisi (su {totale_traiettorie_analisi:,} traiettorie totali di TRAINING):\")\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"{'Window Size':<15} | {'Traiettorie Usabili':<20} | {'Traiettorie Scartate':<20} | {'% Usabili':<10}\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    for timestep in IPERPARAMETRI_TIMESTEP:\n",
    "        traiettorie_usabili = sum(1 for length in all_lengths if length >= timestep)\n",
    "        traiettorie_scartate = totale_traiettorie_analisi - traiettorie_usabili\n",
    "        percentuale_usabili = (traiettorie_usabili / totale_traiettorie_analisi) * 100\n",
    "        print(f\"{timestep:<15} | {traiettorie_usabili:<20} | {traiettorie_scartate:<20} | {percentuale_usabili:<10.2f}%\")\n",
    "\n",
    "    print(\"-\" * 75)\n",
    "    print(\"Analisi completata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb7939",
   "metadata": {},
   "source": [
    "### Normalizzazione\n",
    "\n",
    "Passaggio fondamentale perchè le reti neurali (LSTM/LNN) faticano a imparare quando i dati di input hanno scale completamente diverse. Ad esempio, la colonna COG (rotta) va da 0 a 360, mentre la colonna SOG (velocità) potrebbe andare da 0 a 50. Questi intervalli così diversi \"confondono\" la rete durante l'addestramento.\n",
    "Dobbiamo quindi standardizzarli, portando tutte le colonne a una scala simile.  \n",
    "Il modo corretto per standardizzare è calcolare la media e la deviazione standard dell'intero set di addestramento (tutti i 4.3 milioni di traiettorie nei tuoi 16 file). Ovviamente, questi dati sono troppo grandi per essere caricati tutti insieme in memoria.\n",
    "\n",
    "Quello che facciamo è:  \n",
    "- Inizializziamo uno scaler vuoto e iteriamo sui 16 file di Train.\n",
    "- `partial_fit` è la parte fondamentale perchè per ogni file che carica. Questa funzione dice allo scaler: \"Prendi la media e la deviazione che hai calcolato finora e aggiornale includendo questo nuovo blocco di dati\".\n",
    "- `joblib.dump(scaler, SCALER_PATH)` salva questi parametri calcolati in un file esterno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d81766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando file 1/16: blocco_000-segmentato.parquet\n",
      "Processando file 2/16: blocco_001-segmentato.parquet\n",
      "Processando file 3/16: blocco_002-segmentato.parquet\n",
      "Processando file 4/16: blocco_003-segmentato.parquet\n",
      "Processando file 5/16: blocco_004-segmentato.parquet\n",
      "Processando file 6/16: blocco_005-segmentato.parquet\n",
      "Processando file 7/16: blocco_006-segmentato.parquet\n",
      "Processando file 8/16: blocco_007-segmentato.parquet\n",
      "Processando file 9/16: blocco_008-segmentato.parquet\n",
      "Processando file 10/16: blocco_009-segmentato.parquet\n",
      "Processando file 11/16: blocco_010-segmentato.parquet\n",
      "Processando file 12/16: blocco_011-segmentato.parquet\n",
      "Processando file 13/16: blocco_012-segmentato.parquet\n",
      "Processando file 14/16: blocco_013-segmentato.parquet\n",
      "Processando file 15/16: blocco_014-segmentato.parquet\n",
      "Processando file 16/16: blocco_015-segmentato.parquet\n",
      "\n",
      "Adattamento completato su tutti i 16 file di training.\n",
      "\n",
      "Scaler salvato come 'scaler.joblib'.\n"
     ]
    }
   ],
   "source": [
    "COLONNE_DA_NORMALIZZARE = ['Latitude', 'Longitude', 'SOG', 'COG']\n",
    "SCALER_PATH = 'scaler.joblib'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i, file_path in enumerate(TRAIN_FILES):\n",
    "        \n",
    "        print(f\"Processando file {i+1}/{len(TRAIN_FILES)}: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        df_chunk = pd.read_parquet(file_path, columns=COLONNE_DA_NORMALIZZARE)\n",
    "        \n",
    "        scaler.partial_fit(df_chunk)\n",
    "        \n",
    "        del df_chunk\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"\\nAdattamento completato su tutti i 16 file di training.\")\n",
    "    \n",
    "    joblib.dump(scaler, SCALER_PATH) #Salva file\n",
    "\n",
    "    print(f\"\\nScaler salvato come '{SCALER_PATH}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n Errore durante la preparazione dello scaler: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fb059",
   "metadata": {},
   "source": [
    "#### Funzioni del Data Generator\n",
    "Questo insieme di funzioni costituisce il motore di preparazione dei dati per l'addestramento della rete neurale LSTM, risolvendo il problema di addestrare un modello su milioni di punti di dati (traiettorie) con una memoria di sistema limitata.\n",
    "\n",
    "1. **Funzione di Calcolo Passi per Epoca** *(calculate_steps_per_epoch)*\n",
    "Quando si addestra una rete neurale, è necessario sapere esattamente quanti step (ovvero, quanti batch di dati) compongono un'epoca completa. Questa funzione svolge questo compito in modo sicuro e robusto:\n",
    "\n",
    "   * **Conteggio Sicuro:** La funzione scansiona tutti i file di dati leggendo solo l'ID di ogni traiettoria e contandone la lunghezza, esattamente come nell'analisi precedente. Questo è un processo efficiente in termini di RAM perché non carica tutte le colonne in memoria.\n",
    "\n",
    "   * **Calcolo delle Finestre:** Per ogni traiettoria la cui lunghezza supera la WINDOW_SIZE (la lunghezza di input richiesta dall'LSTM), calcola il numero esatto di finestre temporali che possono essere estratte (una traiettoria lunga 100 punti può generare 100 - WINDOW_SIZE + 1 finestre).\n",
    "\n",
    "   * **Determinazione degli Steps:** Infine, divide il numero totale di finestre (campioni) per la BATCH_SIZE (il numero di campioni elaborati per volta dalla GPU). Il risultato è il numero preciso di steps per epoca che la funzione di training di Keras dovrà eseguire.\n",
    "\n",
    "   Questa precisione è cruciale: se il numero di steps è errato, l'addestramento si blocca o non copre l'intero dataset, compromettendo l'apprendimento.\n",
    "\n",
    "2. **Generatore di Dati Efficace** *(data_generator_v)*\n",
    "Poiché il dataset delle traiettorie è troppo grande per stare nella RAM, non possiamo usare i metodi di caricamento standard. È necessario un Data Generator che agisca come una *fabbrica di dati just-in-time*\n",
    "\n",
    "   * **Lettura Chunkizzata e Sequenziale:** Il generatore legge i file di dati Parquet in piccoli blocchi (CHUNK_SIZE_ROWS) anziché tutto in una volta. Questo assicura che il carico di memoria rimanga basso. \n",
    "\n",
    "   * **Gestione delle Traiettorie a Cavallo:** La sfida principale è che una singola traiettoria può estendersi su più blocchi di dati (chunk) o addirittura su più file. Il generatore utilizza dei buffer temporanei (chunk_buffer e file_buffer) per memorizzare i dati parziali di una traiettoria finché non è completa, garantendo che nessuna sequenza venga interrotta o persa.\n",
    "\n",
    "   * **Creazione delle Finestre:** Per ogni traiettoria completa, la funzione interna *create_windows* estrae tutte le finestre temporali di dimensione WINDOW_SIZE che possono essere generate.\n",
    "\n",
    "   * **Normalizzazione e Yield:**\n",
    "\n",
    "     1. I dati estratti vengono immediatamente normalizzati usando lo scaler pre-calcolato (portandoli sulla scala media 0, deviazione standard 1).\n",
    "\n",
    "     2. Quando il generatore ha abbastanza finestre per riempire un BATCH_SIZE, le impacchetta e le fornisce alla rete neurale tramite l'istruzione yield.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20ffe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funzioni definite\n"
     ]
    }
   ],
   "source": [
    "def calculate_steps_per_epoch(file_paths, window_size, batch_size):\n",
    "    \"\"\"\n",
    "    Scansiona tutti i file in modo efficiente (RAM-safe) per calcolare\n",
    "    il numero totale di finestre (campioni) che verranno generate,\n",
    "    e da lì calcola il numero di \"steps\" (batch) per epoca.\n",
    "    Usa il metodo Counter.update(Series) che sappiamo funzionare.\n",
    "    \"\"\"\n",
    "    print(f\"--- Calcolo Steps per {len(file_paths)} file ---\")\n",
    "    \n",
    "    total_lengths = Counter()\n",
    "    \n",
    "    #Trova le lunghezze di tutte le 4.3M traiettorie\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        print(f\"  Scansione lunghezze file {i+1}/{len(file_paths)}...\", end='\\r')\n",
    "        try:\n",
    "            df = pd.read_parquet(file_path, columns=['TrajectoryID'])\n",
    "            total_lengths.update(df['TrajectoryID'])\n",
    "            del df\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel leggere {file_path}: {e}\")\n",
    "\n",
    "    print(\"\\nScansione completata.\")\n",
    "\n",
    "    #Calcola il numero totale di finestre\n",
    "    total_windows = 0\n",
    "    for length in total_lengths.values():\n",
    "        if length >= window_size:\n",
    "            total_windows += (length - window_size + 1)\n",
    "            \n",
    "    #Calcola gli steps\n",
    "    steps = int(np.ceil(total_windows / batch_size))\n",
    "    \n",
    "    print(f\"Trovate {total_windows:,} finestre totali.\")\n",
    "    print(f\"Steps per Epoca (Batch Size {batch_size}): {steps}\")\n",
    "    print(\"-\" * 75)\n",
    "    return steps\n",
    "\n",
    "\n",
    "def create_windows(data_np, window_size):\n",
    "    windows = []\n",
    "    for i in range(len(data_np) - window_size + 1):\n",
    "        windows.append(data_np[i : i + window_size])\n",
    "    return windows\n",
    "\n",
    "def data_generator_v(file_paths, scaler, features, window_size, batch_size, shuffle_files=False):\n",
    "    \n",
    "    file_buffer = {} \n",
    "    window_buffer = [] \n",
    "    CHUNK_SIZE_ROWS = 500_000\n",
    "\n",
    "    while True:\n",
    "        if shuffle_files:\n",
    "             # Shuffle disattivato forzatamente per garantire la sequenzialità\n",
    "            shuffle_files = False \n",
    "            \n",
    "        for file_path in file_paths:\n",
    "            chunk_buffer = {}\n",
    "            try:\n",
    "                pf = pq.ParquetFile(file_path)\n",
    "                for batch in pf.iter_batches(batch_size=CHUNK_SIZE_ROWS, columns=features + ['TrajectoryID']):\n",
    "                    df_chunk = batch.to_pandas()\n",
    "                    df_chunk[features] = scaler.transform(df_chunk[features])\n",
    "                    next_chunk_buffer = {}\n",
    "                    \n",
    "                    for tid, group in df_chunk.groupby('TrajectoryID'):\n",
    "                        if tid in chunk_buffer:\n",
    "                            trajectory_data = pd.concat([chunk_buffer.pop(tid), group])\n",
    "                        else:\n",
    "                            trajectory_data = group\n",
    "                        \n",
    "                        if tid in file_buffer:\n",
    "                            trajectory_data = pd.concat([file_buffer.pop(tid), trajectory_data])\n",
    "                        \n",
    "                        # Se la traiettoria tocca la fine del chunk, bufferizzala\n",
    "                        if trajectory_data.iloc[-1].name == df_chunk.iloc[-1].name:\n",
    "                            next_chunk_buffer[tid] = trajectory_data\n",
    "                            continue \n",
    "                            \n",
    "                        if len(trajectory_data) < window_size:\n",
    "                            continue \n",
    "                            \n",
    "                        trajectory_np = trajectory_data[features].to_numpy()\n",
    "                        new_windows = create_windows(trajectory_np, window_size)\n",
    "                        window_buffer.extend(new_windows)\n",
    "                        \n",
    "                        next_chunk_buffer[tid] = trajectory_data.iloc[-(window_size - 1):]\n",
    "\n",
    "                        while len(window_buffer) >= batch_size:\n",
    "                            batch_to_yield = window_buffer[:batch_size]\n",
    "                            window_buffer = window_buffer[batch_size:]\n",
    "                            yield (np.array(batch_to_yield), np.array(batch_to_yield))\n",
    "                    \n",
    "                    chunk_buffer = next_chunk_buffer\n",
    "                file_buffer = chunk_buffer\n",
    "            except Exception as e:\n",
    "                print(f\"\\nErrore lettura {file_path}: {e}\")\n",
    "                continue\n",
    "print(\"Funzioni definite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0ab7a",
   "metadata": {},
   "source": [
    "#### Calcolo degli steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac41e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avvio calcolo steps per il Training Set...\n",
      "--- Calcolo Steps per 16 file ---\n",
      "  Scansione lunghezze file 16/16...\n",
      "Scansione lunghezze completata.\n",
      "Trovate 404,801,806 finestre totali.\n",
      "Steps per Epoca (Batch Size 64): 6325029\n",
      "------------------------------------------\n",
      "\n",
      "Avvio calcolo steps per il Validation Set...\n",
      "--- Calcolo Steps per 4 file ---\n",
      "  Scansione lunghezze file 4/4...\n",
      "Scansione lunghezze completata.\n",
      "Trovate 90,369,948 finestre totali.\n",
      "Steps per Epoca (Batch Size 64): 1412031\n",
      "------------------------------------------\n",
      "\n",
      "--- Calcolo Steps Completato ---\n",
      "Training Steps per Epoca: 6325029\n",
      "Validation Steps per Epoca: 1412031\n"
     ]
    }
   ],
   "source": [
    "print(\"Avvio calcolo steps per il Training Set...\")\n",
    "train_steps = calculate_steps_per_epoch(TRAIN_FILES, WINDOW_SIZE, BATCH_SIZE)\n",
    "\n",
    "print(\"\\nAvvio calcolo steps per il Validation Set...\")\n",
    "val_steps = calculate_steps_per_epoch(VAL_FILES, WINDOW_SIZE, BATCH_SIZE)\n",
    "\n",
    "print(\"\\n--- Calcolo Steps Completato ---\")\n",
    "print(f\"Training Steps per Epoca: {train_steps}\")\n",
    "print(f\"Validation Steps per Epoca: {val_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98a059",
   "metadata": {},
   "source": [
    "#### Caricamento Scaler e creazione dei Generatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b71cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizializzazione generatori\n",
      "Generatori pronti.\n"
     ]
    }
   ],
   "source": [
    "print(\"Inizializzazione generatori\")\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "train_gen = data_generator_v(\n",
    "    file_paths=TRAIN_FILES,\n",
    "    scaler=scaler,\n",
    "    features=COLONNE_FEATURES,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_files=False \n",
    ")\n",
    "\n",
    "val_gen = data_generator_v(\n",
    "    file_paths=VAL_FILES,\n",
    "    scaler=scaler,\n",
    "    features=COLONNE_FEATURES,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_files=False\n",
    ")\n",
    "print(\"Generatori pronti.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083506e",
   "metadata": {},
   "source": [
    "#### Definizione Modello LSMT Autoencoder\n",
    "Questa parte del codice descrive la costruzione della rete neurale vera e propria che sarà utilizzata per apprendere e, successivamente, rilevare le anomalie nelle traiettorie delle navi. Il modello implementato è un Autoencoder Sequenziale basato su unità LSTM (Long Short-Term Memory).\n",
    "L'obiettivo di un Autoencoder è imparare una rappresentazione compressa dei dati (il vettore latente) e poi ricostruire l'input originale dall'output.\n",
    "\n",
    "1. La Fase di Codifica **(Encoder)**\n",
    "\n",
    "   * **Input:** La rete accetta come input una finestra temporale (WINDOW_SIZE) con le nostre caratteristiche (**n_features**: Latitudine, Longitudine, SOG, COG).\n",
    "\n",
    "   * **LSTM Encoder:** Lo strato LSTM prende la sequenza completa e la comprime. L'impostazione **return_sequences=False** è cruciale: significa che l'LSTM non restituisce una sequenza completa, ma solo l'ultimo stato nascosto. Questo stato è il vettore latente (latent_dim = 32), che rappresenta la versione compressa e concettuale dell'intera traiettoria di input.\n",
    "\n",
    "2. La Fase di Decodifica **(Decoder)**\n",
    "\n",
    "   * **Repeat Vector:** Il vettore latente (la rappresentazione compressa) viene replicato lungo l'asse temporale per la lunghezza originale della finestra (WINDOW_SIZE). Questo \"spalma\" l'informazione compressa per prepararla alla decodifica.\n",
    "\n",
    "   * **LSTM Decoder:** Un secondo strato LSTM riceve il vettore replicato. Questa volta, **return_sequences=True** indica che deve generare una sequenza completa. Il suo compito è \"srotolare\" il vettore latente e ricostruire la sequenza temporale di output punto per punto.\n",
    "\n",
    "   * **TimeDistributed Dense:** Il layer finale *Dense* è applicato in modo indipendente a ogni singolo punto temporale dell'output del decoder. Questo rimappa i risultati interni dell'LSTM ricostruendo le quattro caratteristiche originali **(n_features)**.\n",
    "\n",
    "3. **Compilazione del Modello**\n",
    "\n",
    "   * **Definizione del Modello:** *Model(inputs, output)* unisce l'encoder e il decoder in un'unica architettura end-to-end.\n",
    "\n",
    "   * **Ottimizzatore (*adam*):** L'algoritmo *Adam* è scelto per l'ottimizzazione del peso del modello, noto per la sua efficacia e velocità.\n",
    "\n",
    "   * **Funzione di Loss** *(loss='mae')*: Viene utilizzata la **Mean Absolute Error (MAE)**. Questa funzione calcola la differenza media assoluta tra la sequenza di traiettoria di input e la sequenza ricostruita in output. Il modello cercherà di minimizzare questo **MAE** durante l'addestramento, imparando a ricostruire le sequenze normali con l'errore più basso possibile.\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb9e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763639954.128417   13211 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4130 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello LSTM-Autoencoder creato e compilato.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │           \u001b[38;5;34m132\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,188</span> (51.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,188\u001b[0m (51.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,188</span> (51.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,188\u001b[0m (51.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_features = len(COLONNE_FEATURES)\n",
    "latent_dim = 32\n",
    "\n",
    "# Encoder\n",
    "inputs = Input(shape=(WINDOW_SIZE, n_features))\n",
    "# Il primo LSTM comprime l'input\n",
    "lstm_encoder = LSTM(latent_dim, return_sequences=False)(inputs)\n",
    "\n",
    "# Decoder\n",
    "# Ripete il vettore compresso per ogni timestep\n",
    "repeat_vector = RepeatVector(WINDOW_SIZE)(lstm_encoder)\n",
    "\n",
    "# Il secondo LSTM \"legge\" il vettore compresso e ricostruisce la sequenza\n",
    "lstm_decoder = LSTM(latent_dim, return_sequences=True)(repeat_vector)\n",
    "\n",
    "# Un layer finale per rimappare l'output\n",
    "output = TimeDistributed(Dense(n_features))(lstm_decoder)\n",
    "\n",
    "model_lstm = Model(inputs, output)\n",
    "model_lstm.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "print(\"Modello LSTM-Autoencoder creato e compilato.\")\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f9710",
   "metadata": {},
   "source": [
    "#### Addestramento LSMT\n",
    "1. **Definizione dei Parametri di Training Ottimali**\n",
    "Prima di iniziare, vengono stabiliti i parametri di dimensione dell'epoca basati su test preliminari eseguiti sulla GPU RTX 4050:\n",
    "\n",
    "   * **STEPS_PER_EPOCH_CALCOLATI (200.000):** Questo valore, ottenuto da analisi di benchmark sulla GPU (come la funzione calculate_steps_per_epoch discussa precedentemente), definisce la quantità di dati che il modello deve vedere per completare un'epoca. Questo numero è stato specificamente calibrato per far sì che ogni epoca duri circa 30 minuti, ottimizzando l'uso delle risorse GPU.\n",
    "\n",
    "   * **VALIDATION_STEPS_CALCOLATI (40.000):** Definisce quanti batch di dati di validazione verranno utilizzati al termine di ogni epoca per valutare le prestazioni su dati non visti.\n",
    "\n",
    "2. **Impostazione dei Callback per un Addestramento Robusto**\n",
    "\n",
    "   * **ModelCheckpoint (Salvataggio del Modello Migliore):** Monitora la val_loss (errore di ricostruzione sul set di validazione). Il suo compito è salvare il modello solo quando si verifica un miglioramento della performance. Questo garantisce che, anche se l'addestramento continua, si mantenga sempre la versione migliore del modello in lstm_autoencoder_best.keras.\n",
    "\n",
    "   * **EarlyStopping (Interruzione Anticipata):** Agisce come un meccanismo di sicurezza. Monitora anch'esso la val_loss e, se non rileva alcun miglioramento per un certo numero di epoche (patience=5), interrompe l'addestramento in anticipo. Questo è cruciale per prevenire l'overfitting (quando il modello impara troppo a memoria i dati di training) e per risparmiare tempo e risorse di calcolo.\n",
    "\n",
    "   * **CSVLogger:** Registra i dettagli dell'addestramento (come la loss e la validation loss di ogni epoca) in un file training_log.csv. Questo permette di analizzare le prestazioni e tracciare le curve di apprendimento anche dopo la fine del processo.\n",
    "\n",
    "3. **Avvio del Processo di Addestramento (model_lstm.fit)**\n",
    "   * **Dati:** Riceve i generatori di dati (train_gen e val_gen), che forniscono continuamente batch di dati normalizzati direttamente dalla memoria di massa, evitando problemi di RAM.\n",
    "\n",
    "   * **Epoche:** Sebbene siano impostate 50 epoche, l'addestramento si affiderà all'EarlyStopping per fermarsi non appena la performance sul set di validazione smette di migliorare.\n",
    "\n",
    "   * **Controllo:** Tutti i callbacks definiti sono attivati per supervisionare e gestire il processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c05ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# E' stato effetuato un test per capire le performance su RTX 4050 e delineare un numero di steps per epoca adeguato per completare un epoca in circa 30 minuti.\n",
    "\n",
    "STEPS_PER_EPOCH_CALCOLATI = 200000\n",
    "VALIDATION_STEPS_CALCOLATI = 40000\n",
    "\n",
    "print(f\"Avvio Addestramento LSTM su GPU RTX 4050\")\n",
    "print(f\"Stima durata epoca: ~32 minuti\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'lstm_autoencoder_best.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,                 # Se non migliora per 5 epoche si stoppa\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('training_log.csv', append=True)\n",
    "\n",
    "try:\n",
    "    history_lstm = model_lstm.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_CALCOLATI,\n",
    "        epochs=50,                                          #Si ferma prima se non migliora quindi abbiamo messo un numero alto\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=VALIDATION_STEPS_CALCOLATI,\n",
    "        callbacks=[checkpoint, early_stopping, csv_logger],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"\\nAddestramento Completato\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nAddestramento interrotto manualmente. Il modello migliore è salvo in 'lstm_autoencoder_best.keras'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
